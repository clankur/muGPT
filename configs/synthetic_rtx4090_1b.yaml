# python -m train --config-name=c4_a100x8x4_1b +paths.model_name=1b
defaults:
- synthetic_base
- _self_

num_hosts: 1

mesh:
  d: 1 
  t: 1

training:
  warmup_steps: 9250
  steps:        92500
  steps_for_lr: 92500
  learning_rate: 1.0e-5 
  tokens:
    batch: 256
    len: 1024
  use_grad_clip: true 
  use_gpu: true

model:
  d_model: 2048
  n_q_per_kv: 1
  n_kv: 16
  d_head: 128
  d_ff: 8192
  vocab: 49
  layers: 8

  base:
    d_model: 2048
    n_q_per_kv: 1
    n_kv: 16
    d_head: 128
    d_ff: 8192
 
  rope_max_timescale: 10000

  # parameters for mixattention
  window_size: 16 
  n_kv_reuses: 2
  shared_kv_idx:
    - 0
    - 1 
    - 1
    - 2
    - 2
    - 0
    - 3
    - 3
  sa_layers:
    - 0 
    - 5 

  # parameters for mup
  a_attn: 1.
  a_output: 1.
  zero_queries: true
  zero_unembed: true

  # parameters for exp scaling
  parameterization: "sp" 
  fully_aligned: false
  gamma_embed: 1.
  gamma_hidden: 1. 
  gamma_unembed: 1. 

checkpoint_interval: 2500
